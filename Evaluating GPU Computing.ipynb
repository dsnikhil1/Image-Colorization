{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that Colorization GPU training results are included in Colorization (Includes GPU Computing) Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPUs were used to achieve best Colorization and Transfer Learning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import copy\n",
    "import cv2\n",
    "import glob\n",
    "import cv2\n",
    "import os \n",
    "from os import path\n",
    "from skimage.color import lab2rgb\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, MSELoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, ConvTranspose2d\n",
    "from torch.optim import Adam, SGD\n",
    "from math import log10, sqrt\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity\n",
    "import argparse\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data function\n",
    "images = []\n",
    "def load_images_from_folder(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        #print(filename)\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            #print('hi')\n",
    "            images.append((img,filename))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAB images\n",
    "images = load_images_from_folder(\"./face_images\")\n",
    "L_images = []\n",
    "ab_images= []\n",
    "for img,filename in images:\n",
    "    imageLAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    L, a, b = cv2.split(imageLAB)\n",
    "    L=np.array(L,dtype=np.float32)\n",
    "    L=L[np.newaxis,:,:]\n",
    "    a=np.array(a,dtype=np.float32)\n",
    "    b=np.array(b,dtype=np.float32)\n",
    "    ab=[]\n",
    "    ab.append(a)\n",
    "    ab.append(b)\n",
    "    ab=np.array(ab)\n",
    "    ab_images.append(torch.tensor(ab))\n",
    "    L_images.append(torch.tensor(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train & Test data\n",
    "train_percentage=90\n",
    "train_size=int((975/100)*train_percentage)\n",
    "test_size=975-train_size\n",
    "all_indices=np.arange(0,975)\n",
    "np.random.shuffle(all_indices)\n",
    "train_L=[]\n",
    "train_ab=[]\n",
    "test_L=[]\n",
    "test_ab=[]\n",
    "for i in all_indices[:train_size]:\n",
    "    train_L.append(L_images[i])\n",
    "    train_ab.append(ab_images[i])\n",
    "for i in all_indices[train_size:]:\n",
    "    test_L.append(L_images[i])\n",
    "    test_ab.append(ab_images[i])\n",
    "train_L=torch.stack(train_L, dim=0)\n",
    "train_ab=torch.stack(train_ab, dim=0)\n",
    "test_L=torch.stack(test_L, dim=0)\n",
    "test_ab=torch.stack(test_ab, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Convnet, self).__init__()\n",
    "\n",
    "        self.convolution_layers = Sequential(\n",
    "            Conv2d(1, 8, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.deconvolution_layers = Sequential(\n",
    "            ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            ConvTranspose2d(16, 8, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            ConvTranspose2d(8, 2, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layers(x)\n",
    "        x = self.deconvolution_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n",
      "Printing train data shape\n",
      "torch.Size([877, 1, 128, 128])\n",
      "Printing train ab shape\n",
      "torch.Size([877, 2, 128, 128])\n",
      "Printing test data shape\n",
      "torch.Size([98, 1, 128, 128])\n",
      "Printing test ab shape\n",
      "torch.Size([98, 2, 128, 128])\n",
      "batch_size: 10\n",
      "num_epochs: 8\n",
      "learning_rate: 0.01\n",
      "batches: 87\n",
      "optimizer: Adam\n",
      "Loss function: MSELoss\n",
      "Convnet(\n",
      "  (convolution_layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "  )\n",
      "  (deconvolution_layers): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): ConvTranspose2d(8, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "  )\n",
      ")\n",
      "Epoch: 0, Loss: 3609.7622070, Testing Loss: 8203239936.000\n",
      "Epoch: 1, Loss: 3609.7045898, Testing Loss: 8050635264.000\n",
      "Epoch: 2, Loss: 3609.6958008, Testing Loss: 7803851776.000\n",
      "Epoch: 3, Loss: 3609.6560059, Testing Loss: 7928084992.000\n",
      "Epoch: 4, Loss: 3609.8059082, Testing Loss: 8026670080.000\n",
      "Epoch: 5, Loss: 3609.8474121, Testing Loss: 7747545088.000\n",
      "Epoch: 6, Loss: 3609.7863770, Testing Loss: 8139257344.000\n",
      "Epoch: 7, Loss: 3609.6125488, Testing Loss: 8052413440.000\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('./colorizer.pkl')\n",
    "device=\"cpu\"\n",
    "print(\"Device\", device)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "num_epochs = 8\n",
    "N=train_size\n",
    "learning_rate = 0.01\n",
    "batches = int(N/batch_size)\n",
    "model = model.float()\n",
    "model.to(device)\n",
    "\n",
    "train_data=copy.deepcopy(train_L)\n",
    "train_data=train_data/255\n",
    "train_data = train_data.to(device)\n",
    "print(\"Printing train data shape\")\n",
    "print(train_data.shape)\n",
    "train_ab = train_ab.to(device)\n",
    "print(\"Printing train ab shape\")\n",
    "print(train_ab.shape)\n",
    "test_data = copy.deepcopy(test_L)\n",
    "test_data = test_data.to(device)\n",
    "test_data=test_data/255\n",
    "print(\"Printing test data shape\")\n",
    "print(test_data.shape)\n",
    "test_ab = test_ab.to(device)\n",
    "print(\"Printing test ab shape\")\n",
    "print(test_ab.shape)\n",
    "\n",
    "\n",
    "error = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"batch_size:\",batch_size)\n",
    "print('num_epochs:',num_epochs)\n",
    "print(\"learning_rate:\",learning_rate)\n",
    "print(\"batches:\",batches)\n",
    "print(\"optimizer:\",'Adam')\n",
    "print(\"Loss function:\",\"MSELoss\")\n",
    "print(model)\n",
    "\n",
    "loss_hist = np.zeros(num_epochs)\n",
    "loss_test_hist = np.zeros(num_epochs)\n",
    "cpu_time=[]\n",
    "training_start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for index in range(batches):\n",
    "        patterns = train_data[index*batch_size:(index+1)*batch_size]\n",
    "        labels = train_ab[index*batch_size:(index+1)*batch_size]\n",
    "        \n",
    "        #print(\"printing all labels shape\")\n",
    "        #print(labels.shape)\n",
    "        # Forward pass \n",
    "        outputs = model(patterns)\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "\n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Propagating the error backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Saving the loss for visualization\n",
    "        loss_hist[epoch] += loss.data\n",
    "        \n",
    "\n",
    "    #test_total\n",
    "    patterns = test_data\n",
    "    labels = test_ab\n",
    "    outputs = model(patterns)\n",
    "    is_correct = torch.subtract(labels,outputs)\n",
    "    loss_test_hist[epoch] += (is_correct.sum()*is_correct.sum())/test_size\n",
    "\n",
    "    \n",
    "    print(\"Epoch: {}, Loss: {:.7f}, Testing Loss: {:.3f}\".format( \n",
    "                        epoch, loss_hist[epoch], loss_test_hist[epoch]))\n",
    "    \n",
    "    cpu_time.append(time.time()-training_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73.6412398815155,\n",
       " 148.5677888393402,\n",
       " 222.3267719745636,\n",
       " 296.60596346855164,\n",
       " 370.39390897750854,\n",
       " 444.7990026473999,\n",
       " 518.5712730884552,\n",
       " 592.2489430904388]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch command for enabling cuda\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Making sure Cuda is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7605\n"
     ]
    }
   ],
   "source": [
    "#Printing the CuDNN version\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrying out garbage collection for preventing out of memory error\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda:3\n",
      "Printing train data shape\n",
      "torch.Size([877, 1, 128, 128])\n",
      "Printing train ab shape\n",
      "torch.Size([877, 2, 128, 128])\n",
      "Printing test data shape\n",
      "torch.Size([98, 1, 128, 128])\n",
      "Printing test ab shape\n",
      "torch.Size([98, 2, 128, 128])\n",
      "batch_size: 10\n",
      "num_epochs: 8\n",
      "learning_rate: 0.01\n",
      "batches: 87\n",
      "optimizer: Adam\n",
      "Loss function: MSELoss\n",
      "Convnet(\n",
      "  (convolution_layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "  )\n",
      "  (deconvolution_layers): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): ConvTranspose2d(8, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "  )\n",
      ")\n",
      "Epoch: 0, Loss: 3609.7021484, Testing Loss: 8434833920.000\n",
      "Epoch: 1, Loss: 3609.7160645, Testing Loss: 8190244352.000\n",
      "Epoch: 2, Loss: 3609.7155762, Testing Loss: 8133899264.000\n",
      "Epoch: 3, Loss: 3609.4206543, Testing Loss: 7879679488.000\n",
      "Epoch: 4, Loss: 3609.8828125, Testing Loss: 7661088768.000\n",
      "Epoch: 5, Loss: 3609.7387695, Testing Loss: 7639442432.000\n",
      "Epoch: 6, Loss: 3609.7001953, Testing Loss: 7627333632.000\n",
      "Epoch: 7, Loss: 3609.7509766, Testing Loss: 7398665728.000\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('./colorizer.pkl')\n",
    "print(\"Device\", device)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "num_epochs = 8\n",
    "N=train_size\n",
    "learning_rate = 0.01\n",
    "batches = int(N/batch_size)\n",
    "model = model.float()\n",
    "model.to(device)\n",
    "\n",
    "train_data=copy.deepcopy(train_L)\n",
    "train_data=train_data/255\n",
    "train_data = train_data.to(device)\n",
    "print(\"Printing train data shape\")\n",
    "print(train_data.shape)\n",
    "train_ab = train_ab.to(device)\n",
    "print(\"Printing train ab shape\")\n",
    "print(train_ab.shape)\n",
    "test_data = copy.deepcopy(test_L)\n",
    "test_data = test_data.to(device)\n",
    "test_data=test_data/255\n",
    "print(\"Printing test data shape\")\n",
    "print(test_data.shape)\n",
    "test_ab = test_ab.to(device)\n",
    "print(\"Printing test ab shape\")\n",
    "print(test_ab.shape)\n",
    "\n",
    "\n",
    "error = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"batch_size:\",batch_size)\n",
    "print('num_epochs:',num_epochs)\n",
    "print(\"learning_rate:\",learning_rate)\n",
    "print(\"batches:\",batches)\n",
    "print(\"optimizer:\",'Adam')\n",
    "print(\"Loss function:\",\"MSELoss\")\n",
    "print(model)\n",
    "\n",
    "loss_hist = np.zeros(num_epochs)\n",
    "loss_test_hist = np.zeros(num_epochs)\n",
    "gpu_time=[]\n",
    "training_start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for index in range(batches):\n",
    "        patterns = train_data[index*batch_size:(index+1)*batch_size]\n",
    "        labels = train_ab[index*batch_size:(index+1)*batch_size]\n",
    "        \n",
    "        #print(\"printing all labels shape\")\n",
    "        #print(labels.shape)\n",
    "        # Forward pass \n",
    "        outputs = model(patterns)\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "\n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Propagating the error backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Saving the loss for visualization\n",
    "        loss_hist[epoch] += loss.data\n",
    "        \n",
    "\n",
    "    #test_total\n",
    "    patterns = test_data\n",
    "    labels = test_ab\n",
    "    outputs = model(patterns)\n",
    "    is_correct = torch.subtract(labels,outputs)\n",
    "    loss_test_hist[epoch] += (is_correct.sum()*is_correct.sum())/test_size\n",
    "\n",
    "    \n",
    "    print(\"Epoch: {}, Loss: {:.7f}, Testing Loss: {:.3f}\".format( \n",
    "                        epoch, loss_hist[epoch], loss_test_hist[epoch]))\n",
    "    \n",
    "    gpu_time.append(time.time()-training_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cpu_time,c='r')\n",
    "plt.plot(gpu_time,c='g')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Training time (s)')\n",
    "plt.legend(['cpu_time','gpu_time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that training on GPU is significantly faster than training on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed up gained with GPU (Extra credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up gained with GPU is 26.968080620495375\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up gained with GPU is {}\".format(cpu_time[-1]/gpu_time[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with GPU is approximately 27 times faster than training with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
